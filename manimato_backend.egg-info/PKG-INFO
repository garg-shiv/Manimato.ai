Metadata-Version: 2.4
Name: manimato-backend
Version: 0.1.0
Summary: Add your description here
Requires-Python: >=3.12
Description-Content-Type: text/markdown
Requires-Dist: fastapi<1.0.0,>=0.115.14
Requires-Dist: langchain==0.1.20
Requires-Dist: langchain-community<1.0.0,>=0.0.38
Requires-Dist: langchain-openai==0.1.7
Requires-Dist: uvicorn[standard]<1.0.0,>=0.35.0
Provides-Extra: dev
Requires-Dist: black>=25.1.0; extra == "dev"
Requires-Dist: ruff>=0.12.2; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: taskipy; extra == "dev"

# FastAPI LLM Service

A FastAPI-based service for LLM interactions using Google's Gemini API and LangChain.

## Features

- **FastAPI Framework**: Modern, fast (high-performance) web framework
- **Gemini Integration**: Google's Gemini AI model integration
- **LangChain Support**: Advanced LLM chain operations
- **Async Operations**: Full async/await support
- **Request Logging**: Comprehensive request/response logging
- **Error Handling**: Custom exception handling
- **CORS Support**: Cross-origin resource sharing
- **Health Checks**: Built-in health check endpoints

## Project Structure

```
your_project/
├── app/
│   ├── api/                        # Entry point for HTTP APIs
│   │   ├── v1/
│   │   │   ├── endpoints/          # Route controllers
│   │   │   │   ├── chat.py
│   │   │   │   └── inference.py
│   │   │   └── router.py
│   ├── core/                       # Core system-wide functionality
│   │   ├── config.py               # Env + settings
│   │   ├── logger.py               # Logging setup
│   │   └── llm_provider.py         # Gemini/LangChain setup
│   ├── services/                   # Business logic layer
│   │   ├── chat_service.py
│   │   ├── chain_manager.py
│   │   └── prompt_templates.py
│   ├── schemas/                    # Pydantic request/response models
│   │   ├── chat.py
│   │   └── inference.py
│   ├── utils/                      # Shared utilities
│   │   ├── retry.py
│   │   └── helpers.py
│   ├── exceptions/                # Custom exception handlers
│   │   └── handlers.py
│   ├── middlewares/              # Custom middlewares (CORS, logging)
│   │   └── request_logger.py
│   ├── main.py                    # FastAPI app
│   └── deps.py                    # Shared dependencies
├── tests/                         # Unit & integration tests
│   ├── api/
│   └── services/
├── .env
├── requirements.txt
├── README.md
├── gunicorn_conf.py              # For production server
├── Dockerfile                    # Optional: for containerization
├── docker-compose.yml           # Optional: multi-service deploy
└── pyproject.toml                # Tooling config (black, isort, etc)
```

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd your_project
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

5. Configure your Gemini API key in `.env`:
```
GEMINI_API_KEY=your_actual_api_key_here
```

## Usage

### Development

Run the development server:
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Or using Python directly:
```bash
python app/main.py
```

### Production

Run with Gunicorn:
```bash
gunicorn app.main:app -c gunicorn_conf.py
```

## API Endpoints

### Health Check
- `GET /health` - Health check endpoint

### Chat API
- `POST /api/v1/chat/chat` - Chat with the LLM

### Inference API
- `POST /api/v1/inference/inference` - Run LLM inference

## API Documentation

Once the server is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## Configuration

Configuration is managed through environment variables. See `.env` file for available options:

- `ENVIRONMENT`: Environment (development/production)
- `DEBUG`: Enable debug mode
- `GEMINI_API_KEY`: Your Gemini API key
- `LLM_MODEL`: Gemini model to use
- `LOG_LEVEL`: Logging level

## Testing

Run tests:
```bash
pytest
```

Run tests with coverage:
```bash
pytest --cov=app
```

## Development Tools

Format code:
```bash
black app/
isort app/
```

Lint code:
```bash
flake8 app/
```

## License

This project is licensed under the MIT License.
